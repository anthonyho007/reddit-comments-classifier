{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"reddit-comment-classification-comp-551/reddit_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"reddit-comment-classification-comp-551/reddit_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddits</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Honestly, Buffalo is the correct answer. I rem...</td>\n",
       "      <td>hockey</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ah yes way could have been :( remember when he...</td>\n",
       "      <td>nba</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He wouldn't have been a bad signing if we woul...</td>\n",
       "      <td>soccer</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Easy. You use the piss and dry technique. Let ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>69995</td>\n",
       "      <td>Thank you, you confirm Spain does have nice pe...</td>\n",
       "      <td>europe</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>69996</td>\n",
       "      <td>Imagine how many he would have killed with a r...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>69997</td>\n",
       "      <td>Yes. Only. As in the guy I was replying to was...</td>\n",
       "      <td>canada</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>69998</td>\n",
       "      <td>Looking for something light-hearted or has a v...</td>\n",
       "      <td>anime</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>69999</td>\n",
       "      <td>I love how I never cry about casters because I...</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           comments  \\\n",
       "0          0  Honestly, Buffalo is the correct answer. I rem...   \n",
       "1          1  Ah yes way could have been :( remember when he...   \n",
       "2          2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...   \n",
       "3          3  He wouldn't have been a bad signing if we woul...   \n",
       "4          4  Easy. You use the piss and dry technique. Let ...   \n",
       "...      ...                                                ...   \n",
       "69995  69995  Thank you, you confirm Spain does have nice pe...   \n",
       "69996  69996  Imagine how many he would have killed with a r...   \n",
       "69997  69997  Yes. Only. As in the guy I was replying to was...   \n",
       "69998  69998  Looking for something light-hearted or has a v...   \n",
       "69999  69999  I love how I never cry about casters because I...   \n",
       "\n",
       "            subreddits  label  \n",
       "0               hockey     11  \n",
       "1                  nba     14  \n",
       "2      leagueoflegends     12  \n",
       "3               soccer     16  \n",
       "4                funny      9  \n",
       "...                ...    ...  \n",
       "69995           europe      8  \n",
       "69996  leagueoflegends     12  \n",
       "69997           canada      6  \n",
       "69998            anime      4  \n",
       "69999  GlobalOffensive      1  \n",
       "\n",
       "[70000 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label each categories\n",
    "train_df.subreddits = pd.Categorical(train_df.subreddits)\n",
    "train_df['label'] = train_df.subreddits.cat.codes\n",
    "label_mapping = dict( enumerate(train_df['subreddits'].cat.categories ) )\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58105    &gt;Is a white writer really not allowed to us...\n",
       "22589    Yeah! Im English and you can be damned sure I ...\n",
       "4183     I saw a (I am guessing) 10 year old get hit in...\n",
       "18670    He was mostly useless every team fight and the...\n",
       "41299    Good luck actually using that healthcare thoug...\n",
       "                               ...                        \n",
       "49100    Add fruit juice in all of its forms to that. S...\n",
       "20609    Not sure if he's still a \"prospect\" but Duclai...\n",
       "21440    ERs in the US can have long wait times too.  I...\n",
       "50057    My 10 is like someone's 5 and smoke fairly often \n",
       "5192     Dee Gordon gets his first homer of the season ...\n",
       "Name: comments, Length: 52500, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df['comments'], train_df['label'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670     Yeah but euron's about to bring cersei tyrion ...\n",
       "49567    All of his videos are sarcastic and funny...hi...\n",
       "50796    I love those scenes but it wouldn't have made ...\n",
       "22310    You do get a smidge of hp for every point of c...\n",
       "54037    New MMORPG lets you play as someone playing a ...\n",
       "                               ...                        \n",
       "32138    Don't want to get into a fight here, but all I...\n",
       "53648    Its the key that opens the gate to the Obsidia...\n",
       "64554    That Barry Zito would be a key part to the Gia...\n",
       "33812    Inb4 triggered Lijang Tower suckers come and c...\n",
       "30231    Is eating in public illegal too?\\n\\nIt is a my...\n",
       "Name: comments, Length: 17500, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52500x61620 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 960433 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize the words\n",
    "\n",
    "cv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17500x61620 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 308971 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cv = cv.transform(X_test)\n",
    "X_test_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model with BNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.4948571428571429\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
